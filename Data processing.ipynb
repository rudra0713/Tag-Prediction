{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Id\",\"Title\",\"Body\",\"Tags\"\n",
      "\n",
      "\"1\",\"How to check if an uploaded file is an image without mime type?\",\"<p>I'd like to check if an uploaded file is an image file (e.g png, jpg, jpeg, gif, bmp) or another file. The problem is that I'm using Uploadify to upload the files, which changes the mime type and gives a 'text/octal' or something as the mime type, no matter which file type you upload.</p>\n",
      "\n",
      "\n",
      "\n",
      "<p>Is there a way to check if the uploaded file is an image apart from checking the file extension using PHP?</p>\n",
      "\n",
      "\",\"php image-processing file-upload upload mime-types\"\n",
      "\n",
      "\"2\",\"How can I prevent firefox from closing when I press ctrl-w\",\"<p>In my favorite editor (vim), I regularly use ctrl-w to execute a certain action. Now, it quite often happens to me that firefox is the active window (on windows) while I still look at vim (thinking vim is the active window) and press ctrl-w which closes firefox. This is not what I want. Is there a way to stop ctrl-w from closing firefox?</p>\n",
      "\n",
      "\n",
      "\n",
      "<p>Rene</p>\n",
      "\n",
      "\",\"firefox\"\n",
      "\n",
      "\"3\",\"R Error Invalid type (list) for variable\",\"<p>I am import matlab file and construct a data frame, matlab file contains two columns with and each row maintain a cell that has a matrix, I construct a dataframe to run random forest. But I am getting following error. </p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xlrd\n",
    "f = open('./data/train.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_text = open(\"all_text_fields.txt\", \"w\")\n",
    "\n",
    "def all_text_field_to_file():\n",
    "    for i in range(10):\n",
    "        line = f.readline()\n",
    "        print(line)\n",
    "    \n",
    "all_text_field_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "import re\n",
    "converted_text = ''\n",
    "img_found = False\n",
    "anchor_found = False\n",
    "code_found = False\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        global converted_text, img_found, anchor_found, code_found\n",
    "        #print(\"starting tag...\", tag)\n",
    "        if 'code' in tag:\n",
    "            code_found = True\n",
    "        if tag == 'img':\n",
    "            converted_text += '<IMG> '\n",
    "        if tag == 'a':\n",
    "            converted_text += '<ANCHOR> '\n",
    "        #print(\"code found start !!! \", code_found)   \n",
    "    def handle_endtag(self, tag):\n",
    "        global converted_text, img_found, anchor_found, code_found\n",
    "        #print(\"ending tag...\", tag)\n",
    "        if tag == 'code':\n",
    "            code_found = False\n",
    "    def handle_data(self, data):\n",
    "        #print(\"data...\", data)\n",
    "        global converted_text, img_found, anchor_found, code_found\n",
    "        str_without_digit = ' ' +  re.sub(r'\\b\\d+(?:\\.\\d+)?\\s+', '', data) # remove digits\n",
    "        final_data = ''.join(str_without_digit.split(\"\\n\")) # remove newlines\n",
    "        final_data = re.sub(r'http\\S+', '', final_data, flags=re.MULTILINE)\n",
    "        if code_found:\n",
    "                converted_text += '<CODE>' + final_data + '<CODE>'\n",
    "        else:  \n",
    "            converted_text += final_data\n",
    "        #print(\"converted text....\", converted_text)    \n",
    "\n",
    "        \n",
    "parser = MyHTMLParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed rowindex  100000\n",
      "id count\n",
      "50175\n",
      "24912\n",
      "24913\n",
      "completed rowindex  200000\n",
      "id count\n",
      "100480\n",
      "49760\n",
      "49760\n",
      "completed rowindex  300000\n",
      "id count\n",
      "150649\n",
      "74675\n",
      "74676\n",
      "completed rowindex  400000\n",
      "id count\n",
      "200586\n",
      "99707\n",
      "99707\n",
      "completed rowindex  500000\n",
      "id count\n",
      "250561\n",
      "124719\n",
      "124720\n",
      "completed rowindex  600000\n",
      "id count\n",
      "300576\n",
      "149712\n",
      "149712\n",
      "completed rowindex  700000\n",
      "id count\n",
      "350436\n",
      "174782\n",
      "174782\n",
      "completed rowindex  800000\n",
      "id count\n",
      "400388\n",
      "199806\n",
      "199806\n",
      "completed rowindex  900000\n",
      "id count\n",
      "450388\n",
      "224806\n",
      "224806\n",
      "completed rowindex  1000000\n",
      "id count\n",
      "500397\n",
      "249801\n",
      "249802\n",
      "completed rowindex  1100000\n",
      "id count\n",
      "550627\n",
      "274686\n",
      "274687\n",
      "completed rowindex  1200000\n",
      "id count\n",
      "600582\n",
      "299709\n",
      "299709\n",
      "completed rowindex  1300000\n",
      "id count\n",
      "650729\n",
      "324635\n",
      "324636\n",
      "completed rowindex  1400000\n",
      "id count\n",
      "700813\n",
      "349593\n",
      "349594\n",
      "completed rowindex  1500000\n",
      "id count\n",
      "750930\n",
      "374535\n",
      "374535\n",
      "completed rowindex  1600000\n",
      "id count\n",
      "800918\n",
      "399541\n",
      "399541\n",
      "completed rowindex  1700000\n",
      "id count\n",
      "850980\n",
      "424510\n",
      "424510\n",
      "completed rowindex  1800000\n",
      "id count\n",
      "901131\n",
      "449434\n",
      "449435\n",
      "completed rowindex  1900000\n",
      "id count\n",
      "951209\n",
      "474395\n",
      "474396\n",
      "completed rowindex  2000000\n",
      "id count\n",
      "1001080\n",
      "499460\n",
      "499460\n",
      "completed rowindex  2100000\n",
      "id count\n",
      "1051193\n",
      "524403\n",
      "524404\n",
      "completed rowindex  2200000\n",
      "id count\n",
      "1101231\n",
      "549384\n",
      "549385\n",
      "completed rowindex  2300000\n",
      "id count\n",
      "1151323\n",
      "574338\n",
      "574339\n",
      "completed rowindex  2400000\n",
      "id count\n",
      "1201479\n",
      "599260\n",
      "599261\n",
      "completed rowindex  2500000\n",
      "id count\n",
      "1293160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  2600000\n",
      "id count\n",
      "1393160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  2700000\n",
      "id count\n",
      "1493160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  2800000\n",
      "id count\n",
      "1593160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  2900000\n",
      "id count\n",
      "1693160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3000000\n",
      "id count\n",
      "1793160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3100000\n",
      "id count\n",
      "1893160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3200000\n",
      "id count\n",
      "1993160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3300000\n",
      "id count\n",
      "2093160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3400000\n",
      "id count\n",
      "2193160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3500000\n",
      "id count\n",
      "2293160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3600000\n",
      "id count\n",
      "2393160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3700000\n",
      "id count\n",
      "2493160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3800000\n",
      "id count\n",
      "2593160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  3900000\n",
      "id count\n",
      "2693160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4000000\n",
      "id count\n",
      "2793160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4100000\n",
      "id count\n",
      "2893160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4200000\n",
      "id count\n",
      "2993160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4300000\n",
      "id count\n",
      "3093160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4400000\n",
      "id count\n",
      "3193160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4500000\n",
      "id count\n",
      "3293160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4600000\n",
      "id count\n",
      "3393160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4700000\n",
      "id count\n",
      "3493160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4800000\n",
      "id count\n",
      "3593160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  4900000\n",
      "id count\n",
      "3693160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5000000\n",
      "id count\n",
      "3793160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5100000\n",
      "id count\n",
      "3893160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5200000\n",
      "id count\n",
      "3993160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5300000\n",
      "id count\n",
      "4093160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5400000\n",
      "id count\n",
      "4193160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5500000\n",
      "id count\n",
      "4293160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5600000\n",
      "id count\n",
      "4393160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5700000\n",
      "id count\n",
      "4493160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5800000\n",
      "id count\n",
      "4593160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  5900000\n",
      "id count\n",
      "4693160\n",
      "603420\n",
      "603420\n",
      "completed rowindex  6000000\n",
      "id count\n",
      "4793160\n",
      "603420\n",
      "603420\n",
      "done\n",
      "id count\n",
      "4827355\n",
      "603420\n",
      "603420\n"
     ]
    }
   ],
   "source": [
    "import csv, random, codecs\n",
    "sample_train = open('sample_train.csv', mode='w')\n",
    "sample_train_writer = csv.writer(sample_train, delimiter=',')\n",
    "sample_train_writer.writerow([\"Id\", \"Title\", \"Body\", \"Tag\"])\n",
    "\n",
    "sample_dev = open('sample_dev.csv', mode='w')\n",
    "sample_dev_writer = csv.writer(sample_dev, delimiter=',')\n",
    "sample_dev_writer.writerow([\"Id\", \"Title\", \"Body\", \"Tag\"])\n",
    "\n",
    "sample_test = open('sample_test.csv', mode='w')\n",
    "sample_test_writer = csv.writer(sample_test, delimiter=',')\n",
    "sample_test_writer.writerow([\"Id\", \"Title\", \"Body\", \"Tag\"])\n",
    "\n",
    "dev_len = 0\n",
    "test_len = 0\n",
    "train_len = 0\n",
    "dev_write = False\n",
    "\n",
    "dev_done = False\n",
    "test_done = False\n",
    "\n",
    "count = 0\n",
    "\n",
    "reader = csv.reader(codecs.open('./data/train.csv', 'rU', 'utf-8'))\n",
    "for rowIndex, row in enumerate(reader):\n",
    "    if 0 < rowIndex:\n",
    "        row_content = list(row)\n",
    "#             for index, item in enumerate(row):\n",
    "#                 if index == 2:\n",
    "#                     parser.feed(item)\n",
    "#                     row_content.append(converted_text)\n",
    "#                 else:\n",
    "#                     row_content.append(item)\n",
    "#             row_content.append(row)        \n",
    "            #print(\"Final converted text..... \", converted_text)\n",
    "        if None in row_content:\n",
    "            print(\"found none \", rowIndex)\n",
    "            continue\n",
    "        converted_text = ''\n",
    "        img_found = False\n",
    "        anchor_found = False\n",
    "        code_found = False\n",
    "#         sample_train_writer.writerow(row_content)\n",
    "        if dev_done and test_done:\n",
    "            sample_train_writer.writerow(row_content)\n",
    "            train_len += 1\n",
    "        else:\n",
    "            rand_float = random.random()\n",
    "            if rand_float >= 0.5:\n",
    "                sample_train_writer.writerow(row_content)\n",
    "                train_len += 1\n",
    "            else:\n",
    "                if dev_done:\n",
    "                    sample_test_writer.writerow(row_content)\n",
    "                    test_len += 1\n",
    "                elif test_done:\n",
    "                    sample_dev_writer.writerow(row_content)\n",
    "                    dev_len += 1\n",
    "                elif dev_write:\n",
    "                    sample_dev_writer.writerow(row_content)\n",
    "                    dev_len += 1\n",
    "                elif not dev_write:\n",
    "                    sample_test_writer.writerow(row_content)\n",
    "                    test_len += 1\n",
    "                if dev_len >= 603420:\n",
    "                    dev_done = True\n",
    "                if test_len >= 603420:\n",
    "                    test_done = True\n",
    "                dev_write = not dev_write        \n",
    "        if rowIndex % 100000 == 0:\n",
    "            print(\"completed rowindex \", rowIndex)\n",
    "            print(\"id count\")\n",
    "            print(train_len)\n",
    "            print(dev_len)\n",
    "            print(test_len)\n",
    "#     if rowIndex == 100:\n",
    "#         break\n",
    "\n",
    "print(\"done\")\n",
    "# reader = csv.reader(codecs.open('./sample_train.csv', 'rU', 'utf-8'))\n",
    "# row_count = sum(1 for row in reader)  \n",
    "# print(row_count)    \n",
    "# reader = csv.reader(codecs.open('./sample_dev.csv', 'rU', 'utf-8'))\n",
    "# row_count = sum(1 for row in reader)  \n",
    "# print(row_count)    \n",
    "# reader = csv.reader(codecs.open('./sample_test.csv', 'rU', 'utf-8'))\n",
    "# row_count = sum(1 for row in reader)  \n",
    "# print(row_count)    \n",
    "print(\"id count\")\n",
    "print(train_len)\n",
    "print(dev_len)\n",
    "print(test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found tag  p\n",
      "found tag  img\n",
      "data... Hello world\n",
      "final data  Hello world\n",
      "end tag  p\n",
      "conv  <IMG> Hello world\n"
     ]
    }
   ],
   "source": [
    "global converted_text\n",
    "parser.feed('<p><img src=\"\"http://i.stack.imgur.com/bA7Tz.jpg\"\" alt=\"\"http://m1.img.libdd.com/farm4/2013/0528/10/959DCB60497E3C74E998958C2F4674DB2E9198943E62C_1280_487.jpg\"\">Hello world</p>')\n",
    "print(\"conv \", converted_text)\n",
    "converted_text = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world. I want to show you that abc does not work.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = 'hello world. I want to show you that abchttp.google.com does not work.'\n",
    "text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there anyone? He the best. How about you?\n",
      "about you? Is there best. How He anyone? the\n",
      "[1, 2, 3, 3, 4, 5]\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "string1 = \"Is there anyone? He Is the best. How about you?\"\n",
    "words = string1.split()\n",
    "print(\" \".join(sorted(set(words), key=words.index)))\n",
    "print(\" \".join(set(words)))\n",
    "x = []\n",
    "y = [1,2,3]\n",
    "x += y\n",
    "z = [3,4,5]\n",
    "x += z\n",
    "print(x)\n",
    "print(set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all tags\n",
      "41397\n",
      "all tags count\n",
      "41397\n",
      "['c#', 'java', 'php', 'javascript', 'android', 'jquery', 'c++', 'python', 'iphone', 'asp.net']\n",
      "[370910, 329604, 314397, 292649, 256289, 244571, 159250, 147733, 147154, 142044]\n",
      "500 th tag  python-3.x 3951\n"
     ]
    }
   ],
   "source": [
    "all_tags = []\n",
    "all_tags_count = []\n",
    "import json\n",
    "\n",
    "with open('./sample_train.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for rowIndex, row in enumerate(reader):\n",
    "        if 0 < rowIndex:\n",
    "            for index, column in enumerate(row):\n",
    "                    if index == 3:\n",
    "                        tags = column.split(\" \")\n",
    "                        for tag in tags:\n",
    "                            if tag not in all_tags:\n",
    "                                all_tags.append(tag)\n",
    "                                all_tags_count.append(1)\n",
    "                            else:\n",
    "                                all_tags_count[all_tags.index(tag)] += 1\n",
    "                    \n",
    "#         if rowIndex == 50000:\n",
    "#             break\n",
    "print(\"all tags\")\n",
    "print(len(all_tags))\n",
    "print(\"all tags count\")\n",
    "print(len(all_tags_count))\n",
    "\n",
    "tuple_count, tuple_tags = zip(*sorted(zip(all_tags_count, all_tags), reverse=True))\n",
    "list_tags = list(tuple_tags)\n",
    "list_count = list(tuple_count)\n",
    "\n",
    "tags_list_file = {\n",
    "    'tags': list_tags,\n",
    "    'count': list_count\n",
    "}\n",
    "print(list_tags[:10])\n",
    "print(list_count[:10])\n",
    "print(\"500 th tag \", list_tags[500], list_count[500])\n",
    "with open('tags.json', 'w') as outfile:\n",
    "    json.dump(tags_list_file, outfile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6034196\n"
     ]
    }
   ],
   "source": [
    "with open('./data/train.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    row_count = sum(1 for row in reader)  \n",
    "    print(row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_50000 = open('sample_train_50000.csv', mode='w')\n",
    "sample_train_50000_writer = csv.writer(sample_train_50000, delimiter=',')\n",
    "sample_train_50000_writer.writerow([\"Id\", \"Title\", \"Body\", \"Tag\"])\n",
    "\n",
    "\n",
    "reader = csv.reader(codecs.open('./sample_train.csv', 'rU', 'utf-8'))\n",
    "for rowIndex, row in enumerate(reader):\n",
    "    sample_train_50000_writer.writerow(row)\n",
    "    if rowIndex == 50000:\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I [am] good s I am bad I  [] and only\n",
      "['I', '[am]', 'good.', '', 'am', 'bad.', '', '[0.00001]', '[0.00002]', 'and', 'only']\n",
      "I [am] good. am bad. [0.00001] [0.00002] and only \n"
     ]
    }
   ],
   "source": [
    "data = 'I [am] good. 23s I am bad. I 1.00001 [0.00002] and only'\n",
    "str_without_digit = data.translate({ord(ch): None for ch in '0123456789.'})\n",
    "print(str_without_digit)\n",
    "\n",
    "\n",
    "text = 'I [am] good. I am bad. I [0.00001] [0.00002] and only'.split()\n",
    "for i in range(len(text)):\n",
    "    try:\n",
    "        y = float(text[i])\n",
    "        text[i] = ''\n",
    "    except:\n",
    "        continue\n",
    "for i in range(len(text) - 1):\n",
    "    for j in range(i+1, len(text)):\n",
    "        if text[i] == text[j] and text[j] != '' and text[i] != '':\n",
    "            text[j] = ''\n",
    "print(text)\n",
    "text_re = ''.join(str(e) + ' ' for e in text if e != '' and not e.isdigit())\n",
    "print(text_re)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written  100\n",
      "written  1000\n",
      "written  10000\n",
      "written  100000\n"
     ]
    }
   ],
   "source": [
    "import csv, codecs, random\n",
    "def create_dataset(count, prob):\n",
    "    sample_dev = open('sample_dev_' + str(count) + '.csv', mode='w')\n",
    "    sample_dev_writer = csv.writer(sample_dev, delimiter=',')\n",
    "    sample_dev_writer.writerow([\"Id\", \"Title\", \"Body\", \"Tag\"])\n",
    "\n",
    "    line = 0\n",
    "    reader = csv.reader(codecs.open('./sample_dev.csv', 'rU', 'utf-8'))\n",
    "    for rowIndex, row in enumerate(reader):\n",
    "        x = random.random()\n",
    "        if x < prob:\n",
    "            sample_dev_writer.writerow(row)\n",
    "            line += 1\n",
    "            if line == count:\n",
    "                break\n",
    "    print(\"written \", line)\n",
    "    return\n",
    "                \n",
    "create_dataset(100, 0.2)\n",
    "create_dataset(1000, 0.4)\n",
    "create_dataset(10000, 0.6)\n",
    "create_dataset(100000, 0.7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all tags\n",
      "230\n",
      "all tags count\n",
      "230\n",
      "['java', 'php', 'c#', '.net', 'python', 'ios', 'android', 'xml', 'linux', 'javascript']\n",
      "[11, 10, 9, 6, 5, 5, 5, 4, 4, 4]\n",
      "all tags\n",
      "1365\n",
      "all tags count\n",
      "1365\n",
      "['php', 'c#', 'java', 'javascript', 'jquery', 'android', 'html', 'ios', 'python', 'mysql']\n",
      "[76, 72, 70, 67, 54, 53, 39, 34, 33, 32]\n",
      "all tags\n",
      "6193\n",
      "all tags count\n",
      "6193\n",
      "['c#', 'php', 'java', 'javascript', 'android', 'jquery', 'iphone', 'python', 'c++', 'html']\n",
      "[739, 660, 655, 596, 517, 459, 324, 318, 313, 281]\n",
      "all tags\n",
      "18548\n",
      "all tags count\n",
      "18548\n",
      "['c#', 'java', 'php', 'javascript', 'android', 'jquery', 'c++', 'python', 'iphone', 'asp.net']\n",
      "[7798, 6736, 6611, 6058, 5279, 4945, 3330, 3142, 3102, 2944]\n"
     ]
    }
   ],
   "source": [
    "def create_tagset(count):\n",
    "    all_tags = []\n",
    "    all_tags_count = []\n",
    "    import json\n",
    "\n",
    "    with open('./sample_train_' + str(count) + '.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for rowIndex, row in enumerate(reader):\n",
    "            if 0 < rowIndex:\n",
    "                for index, column in enumerate(row):\n",
    "                        if index == 3:\n",
    "                            tags = column.split(\" \")\n",
    "                            for tag in tags:\n",
    "                                if tag not in all_tags:\n",
    "                                    all_tags.append(tag)\n",
    "                                    all_tags_count.append(1)\n",
    "                                else:\n",
    "                                    all_tags_count[all_tags.index(tag)] += 1\n",
    "\n",
    "    #         if rowIndex == 50000:\n",
    "    #             break\n",
    "    print(\"all tags\")\n",
    "    print(len(all_tags))\n",
    "    print(\"all tags count\")\n",
    "    print(len(all_tags_count))\n",
    "\n",
    "    tuple_count, tuple_tags = zip(*sorted(zip(all_tags_count, all_tags), reverse=True))\n",
    "    list_tags = list(tuple_tags)\n",
    "    list_count = list(tuple_count)\n",
    "\n",
    "    tags_list_file = {\n",
    "        'tags': list_tags,\n",
    "        'count': list_count\n",
    "    }\n",
    "    print(list_tags[:10])\n",
    "    print(list_count[:10])\n",
    "    with open('tags_' + str(count) + '.json', 'w') as outfile:\n",
    "        json.dump(tags_list_file, outfile)\n",
    "\n",
    "\n",
    "create_tagset(100)\n",
    "create_tagset(1000)\n",
    "create_tagset(10000)\n",
    "create_tagset(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
